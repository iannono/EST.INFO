upstream estao {
  # for UNIX domain socket setups:
  server unix:/tmp/unicorn.estao.socket fail_timeout=0;

  # for TCP setups, point these to your backend servers
  # server 192.168.0.7:8080 fail_timeout=0;
  # server 192.168.0.8:8080 fail_timeout=0;
}

server {
  listen 80;
  server_name estao.info;

  root /home/estao/apps/estao/current/public;
  access_log /var/log/nginx/estao-access.log;
  rewrite_log on;

  client_max_body_size 4G;
  keepalive_timeout 5;

  location / {
    #all requests are sent to the UNIX socket
    proxy_pass  http://estao;
    proxy_redirect     off;

    proxy_set_header   Host             $host;
    proxy_set_header   X-Real-IP        $remote_addr;
    proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;

    client_max_body_size       10m;
    client_body_buffer_size    128k;

    proxy_connect_timeout      90;
    proxy_send_timeout         90;
    proxy_read_timeout         90;

    proxy_buffer_size          4k;
    proxy_buffers              4 32k;
    proxy_busy_buffers_size    64k;
    proxy_temp_file_write_size 64k;
  }

  # if the request is for a static resource, nginx should serve it directly
  # and add a far future expires header to it, making the browser
  # cache the resource and navigate faster over the website
  # this probably needs some work with Rails 3.1's asset pipe_line
  location ~ ^/(assets)/  {
    root /home/estao/apps/estao/current/public;
    gzip_static on;
    expires max;
    add_header Cache-Control public;
    break;
  }

  location ~ ^/(uploads)/  {
    root /home/estao/apps/estao/current/public;
    expires max;
    break;
  }

  # Rails error pages
  error_page 500 502 503 504 /500.html;
  location = /500.html {
    root /home/estao/apps/estao/current/public;
  }
}
